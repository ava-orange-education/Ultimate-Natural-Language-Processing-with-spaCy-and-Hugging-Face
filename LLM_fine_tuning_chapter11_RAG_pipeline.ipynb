{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Fine-Tuning Step-by-Step\n",
    "\n",
    "#### Step 1: Load the Dataset, tokenizer, and model\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86306ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step 2: Preprocess the Data\n",
    "\n",
    "def preprocess(example):\n",
    "    inputs = tokenizer(example[\"article\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    labels = tokenizer(example[\"highlights\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_data = dataset.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3: Use the Trainer API\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"validation\"]\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5134ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Case Study: Fine-Tuning a Text Summarizer\n",
    "\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"  # Common summarization model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Create summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Get samples using the proper method for datasets\n",
    "small_validation = dataset[\"validation\"].select(range(9))\n",
    "\n",
    "# Extract articles and highlights as lists to avoid indexing issues\n",
    "sample_texts = [item for item in small_validation[\"article\"]]\n",
    "reference_summaries = [item for item in small_validation[\"highlights\"]]\n",
    "\n",
    "# Generate summaries with proper error handling\n",
    "generated_summaries = []\n",
    "for text in sample_texts:\n",
    "    try:\n",
    "        # Handle text that's too long\n",
    "        if len(text) > 1024:  # Simple truncation for very long texts\n",
    "            text = text[:1024]\n",
    "        \n",
    "        # Generate the summary and add explicit error handling\n",
    "        summary_output = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
    "        \n",
    "        # Check if the output is valid\n",
    "        if summary_output and isinstance(summary_output, list) and len(summary_output) > 0:\n",
    "            summary = summary_output[0][\"summary_text\"]\n",
    "            generated_summaries.append(summary)\n",
    "        else:\n",
    "            # Fallback if summary generation fails\n",
    "            print(f\"Warning: Failed to generate summary, using placeholder\")\n",
    "            generated_summaries.append(\"Summary generation failed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        generated_summaries.append(\"Error in summary generation.\")\n",
    "\n",
    "# Make sure we have the same number of generated and reference summaries\n",
    "assert len(generated_summaries) == len(reference_summaries), \"Mismatch in number of summaries\"\n",
    "\n",
    "# Evaluate with ROUGE\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "results = rouge.compute(predictions=generated_summaries, references=reference_summaries)\n",
    "\n",
    "# Print results\n",
    "print(\"ROUGE Evaluation:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d0df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6f24b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1508\\AppData\\Local\\Temp\\ipykernel_24688\\2800405696.py:16: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embedding = HuggingFaceEmbeddings()\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Query: What is data visualization ?\n",
      "‚úÖ Generated Answer:\n",
      " The term ‚Äúdata visualization‚Äù refers to how you can display numbers, statistics, and other data in a diagram or graph to make it easier to understand and present.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import pipeline\n",
    "\n",
    "# Step 1: Load PDF Document\n",
    "loader = PyPDFLoader(\"HubSpots Guide to Data Analytics.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Step 2: Split into smaller chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=150)\n",
    "docs = splitter.split_documents(documents)\n",
    "\n",
    "# Step 3: Create a vector store with HuggingFace embeddings\n",
    "embedding = HuggingFaceEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# Step 4: Retrieve top-k relevant documents\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})  # Increased k for more context\n",
    "query = \"What is data visualization ?\"\n",
    "\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "context = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "# Truncate context if it's too long\n",
    "context = context[:2000]  # Limit to avoid max_length cutoff\n",
    "\n",
    "# Step 5: Load a better generative QA pipeline\n",
    "model_name = \"google/flan-t5-large\"\n",
    "qa_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model_name,\n",
    "    tokenizer=model_name,\n",
    "    max_length=300,  # Allow longer responses\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# Step 6: Refine prompt to encourage longer, clearer answers\n",
    "prompt = f\"\"\"You are a helpful assistant.\n",
    "Based on the following context, answer the question clearly and in 2-4 informative sentences.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "response = qa_pipeline(prompt)[0][\"generated_text\"]\n",
    "\n",
    "print(\"\\nüìÑ Query:\", query)\n",
    "print(\"‚úÖ Generated Answer:\\n\", response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c148b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-01 13:02:55.527 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\1508\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# app.py\n",
    "\n",
    "import streamlit as st\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load model and setup pipeline\n",
    "@st.cache_resource\n",
    "def load_qa_pipeline():\n",
    "    model_name = \"google/flan-t5-large\"\n",
    "    return pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model_name,\n",
    "        tokenizer=model_name,\n",
    "        max_length=300,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "    )\n",
    "\n",
    "qa_pipeline = load_qa_pipeline()\n",
    "\n",
    "st.title(\"üìÑ PDF Q&A using RAG (FAISS + Flan-T5)\")\n",
    "st.markdown(\"Upload a PDF, ask any question based on its content.\")\n",
    "\n",
    "# Upload PDF\n",
    "uploaded_file = st.file_uploader(\"Upload a PDF document\", type=\"pdf\")\n",
    "\n",
    "if uploaded_file:\n",
    "    st.success(\"PDF uploaded successfully!\")\n",
    "\n",
    "    # Process PDF\n",
    "    loader = PyPDFLoader(uploaded_file)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split into chunks\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=150)\n",
    "    docs = splitter.split_documents(documents)\n",
    "\n",
    "    # Create vector store\n",
    "    embedding = HuggingFaceEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(docs, embedding)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "    # Accept user query\n",
    "    query = st.text_input(\"Ask a question based on the PDF content:\")\n",
    "\n",
    "    if query:\n",
    "        relevant_docs = retriever.get_relevant_documents(query)\n",
    "        context = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "        context = context[:2000]\n",
    "\n",
    "        prompt = f\"\"\"You are a helpful assistant.\n",
    "Based on the following context, answer the question clearly and in 2-4 informative sentences.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "        response = qa_pipeline(prompt)[0][\"generated_text\"]\n",
    "        st.markdown(\"### ‚úÖ Answer:\")\n",
    "        st.write(response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa1c5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.55 (from langchain)\n",
      "  Downloading langchain_core-0.3.56-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.38-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\1508\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (2.1)\n",
      "Downloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 0.8/1.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.56-py3-none-any.whl (437 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.38-py3-none-any.whl (359 kB)\n",
      "Downloading orjson-3.10.18-cp312-cp312-win_amd64.whl (134 kB)\n",
      "Installing collected packages: orjson, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed langchain-0.3.24 langchain-core-0.3.56 langchain-text-splitters-0.3.8 langsmith-0.3.38 orjson-3.10.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e436ab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (0.3.56)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (0.3.24)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (8.2.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (0.3.38)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\1508\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 524.3 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.5/2.5 MB 524.3 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.8/2.5 MB 550.1 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.8/2.5 MB 550.1 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.8/2.5 MB 550.1 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 0.8/2.5 MB 550.1 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 453.5 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 453.5 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 453.5 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 453.5 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.0/2.5 MB 453.5 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.3/2.5 MB 383.5 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.3/2.5 MB 383.5 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 1.6/2.5 MB 405.3 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 1.6/2.5 MB 405.3 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 428.3 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 428.3 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 2.1/2.5 MB 446.6 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.1/2.5 MB 446.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 469.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 479.6 kB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, typing-inspect, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.23 marshmallow-3.26.1 pydantic-settings-2.9.1 typing-inspect-0.9.0 typing-inspection-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872e2c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35868bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sentence-transformers) (0.29.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\1508\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\1508\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc65bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\1508\\appdata\\local\\anaconda31\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\1508\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl (15.0 MB)\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.0 MB 3.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.8/15.0 MB 3.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 2.4/15.0 MB 3.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 3.1/15.0 MB 3.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.9/15.0 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 4.7/15.0 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.0/15.0 MB 3.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.8/15.0 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.3/15.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.8/15.0 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.6/15.0 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 8.1/15.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 8.7/15.0 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 9.4/15.0 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.7/15.0 MB 3.1 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 10.5/15.0 MB 3.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.0/15.0 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.5/15.0 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.1/15.0 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.6/15.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.1/15.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.6/15.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.2/15.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.7/15.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.0/15.0 MB 2.8 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f607fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
